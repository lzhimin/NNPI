{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Quantify the difference of difference feature of neural network after a certain amount of network pruning.\n",
    "### 2. Understand the subnetwork overlap between different neural network samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# import the model of neural network\n",
    "from python.model import LeNet, LeNet_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='PyTorch MNIST pruning from deep compression paper')\n",
    "parser.add_argument('--batch-size', type=int, default=100, metavar='N',\n",
    "                    help='input batch size for training (default: 50)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=100, metavar='N',\n",
    "                    help='number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
    "                    help='random seed (default: 42)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--log', type=str, default='log.txt',\n",
    "                    help='log file name')\n",
    "parser.add_argument('--sensitivity', type=float, default=2,\n",
    "                    help=\"sensitivity value that is multiplied to layer's std in order to get threshold value\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "#the device used for training\n",
    "device = 'cpu'#torch.device(\"cuda\" if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training data\n",
    "mnist = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ]))\n",
    "\n",
    "'''\n",
    "    create feature implace dataset\n",
    "'''\n",
    "#count = 5500\n",
    "#test_loader = torch.utils.data.DataLoader(mnist)\n",
    "#subset_indexes = []\n",
    "#index = 0\n",
    "#with torch.no_grad():\n",
    "#    for data, target in test_loader:\n",
    "#        device_data, device_target = data.to('cpu'), target.to('cpu')\n",
    "#        if count > 0 and target == 0:\n",
    "#            count -= 1\n",
    "#            index += 1\n",
    "#            continue\n",
    "#        else:\n",
    "#            subset_indexes.append(index)\n",
    "#            index += 1\n",
    "        \n",
    "#mnist = torch.utils.data.Subset(mnist, list(range(3000)))\n",
    "train_loader = torch.utils.data.DataLoader(mnist, batch_size=args.batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "# load the testing data\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = '../data/model/letnet_bias'  # model checkpoints\n",
    "# make checkpoint path directory\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def save(model, name):\n",
    "    path = os.path.join(\n",
    "        CHECKPOINT_DIR, 'model_{}.pkl'.format(name))\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "    \n",
    "def train(epochs, model, device, optimizer):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        save(model, str(epoch))\n",
    "        test(model, device)\n",
    "\n",
    "\n",
    "def test(model, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    flag = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        print('Test set: Average loss:', test_loss,\n",
    "              'Accuracy', correct/len(test_loader.dataset))\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inner_State_Difference_Quantification:\n",
    "    def __init__(self, model, pruned_model, samples):\n",
    "        self.model = model\n",
    "        self.pruned_model = model\n",
    "        self.samples = samples\n",
    "        \n",
    "    def getInnerStateRepresentation(self):\n",
    "        return self.model.getInnerState(self.samples)\n",
    "    \n",
    "    def saliencyMap(self):\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.3059203907251358 Accuracy 0.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:11<00:00, 53.43it/s]\n",
      "  0%|                                                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.2713622331491403 Accuracy 0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:11<00:00, 53.96it/s]\n",
      "  0%|                                                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.1879172479834643 Accuracy 0.9427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:09<00:00, 66.22it/s]\n",
      "  0%|                                                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.1421542904417028 Accuracy 0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:09<00:00, 61.30it/s]\n",
      "  0%|                                                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.11957704122020454 Accuracy 0.9636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:31<00:00, 18.88it/s]\n",
      "  0%|                                                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.1007671627737071 Accuracy 0.9694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:08<00:00, 66.73it/s]\n",
      "  0%|                                                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.09576021982306922 Accuracy 0.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:08<00:00, 70.17it/s]\n",
      "  0%|                                                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.08107472876005438 Accuracy 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:08<00:00, 69.62it/s]\n",
      "  0%|                                                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.07733136297626533 Accuracy 0.9747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:09<00:00, 63.21it/s]\n",
      "  0%|                                                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.07586093284512406 Accuracy 0.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:08<00:00, 70.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.07666409314486038 Accuracy 0.9763\n",
      "Test set: Average loss: 0.07666409314486038 Accuracy 0.9763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97.63"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load different neural network model\n",
    "model = LeNet(mask=True).to(device)\n",
    "#model = LeNet_5(mask=True).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
    "#model.load_state_dict(torch.load('../data/model/letnet_bias/model_9.pkl'))\n",
    "#test(model, device)\n",
    "#model.load_state_dict(torch.load('../data/model/LetNet/letnet_5_trained.pkl'))\n",
    "\n",
    "#model.prune_by_percentile(97)\n",
    "#train(10, model, device, optimizer)\n",
    "#test(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# subnetwork overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#path = os.path.join('../data/model/LetNet', 'model_{}.pkl'.format('odd'))\n",
    "#torch.save(model.state_dict(), path)\n",
    "dataset = {}\n",
    "count = 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    device_data, device_target = data.to('cpu'), target.to('cpu')\n",
    "    label = device_target.item()\n",
    "    \n",
    "    if label in dataset:\n",
    "        dataset[label].append(device_data.tolist())\n",
    "    else:\n",
    "        if label == 0 and count > 0:\n",
    "            count-=1\n",
    "            continue\n",
    "        dataset[label] = [device_data.tolist()]\n",
    "    \n",
    "keys = list(dataset.keys())\n",
    "keys.sort()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = {}\n",
    "fc2 = {}\n",
    "layer1 = {}\n",
    "layer2 = {}\n",
    "for k in keys:\n",
    "    rs = model.activationPattern(dataset[k])\n",
    "    fc1[k] = rs['fc1']\n",
    "    fc2[k] = rs['fc2']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keys:\n",
    "    layer1[k] = set(np.where(np.array(fc1[k]) > 250)[0].tolist())\n",
    "    layer2[k] = set(np.where(np.array(fc2[k]) > 250)[0].tolist())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 54\n",
      "layer1 0.5443037974683544\n",
      "layer2 0.6851851851851852\n",
      "layer1 1.0\n",
      "layer2 1.0\n",
      "layer1 0.6329113924050633\n",
      "layer2 0.7592592592592593\n",
      "layer1 0.5569620253164557\n",
      "layer2 0.6111111111111112\n",
      "layer1 0.6582278481012658\n",
      "layer2 0.7777777777777778\n",
      "layer1 0.6455696202531646\n",
      "layer2 0.6666666666666666\n",
      "layer1 0.6329113924050633\n",
      "layer2 0.7222222222222222\n",
      "layer1 0.5569620253164557\n",
      "layer2 0.7037037037037037\n",
      "layer1 0.6708860759493671\n",
      "layer2 0.7592592592592593\n",
      "layer1 0.5949367088607594\n",
      "layer2 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(len(layer1[index]), len(layer2[index]))\n",
    "for i in range(0, 10):\n",
    "    print('layer1',len(layer1[index] & layer1[i])/len(layer1[index]))\n",
    "    print('layer2',len(layer2[index] & layer2[i])/len(layer2[index]))\n",
    "# &  layer1[2] & layer1[3] & layer1[4] & layer1[5] & layer1[6] & layer1[7] & layer1[8] & layer1[9]) \n",
    "#print(layer1[0] | layer1[1] |  layer1[2] | layer1[3] | layer1[4] | layer1[5] | layer1[6] | layer1[7] | layer1[8] | layer1[9]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(layer2[0] & layer2[1] &  layer2[2] & layer2[3] & layer2[4] & layer2[5] & layer2[6] & layer2[7] & layer2[8] & layer2[9]) \n",
    "#print(layer2[0] | layer2[1] |  layer2[2] | layer2[3] | layer2[4] | layer2[5] | layer2[6] | layer2[7] | layer2[8] | layer2[9]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
